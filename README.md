# Signavio Workflow Accelerator Connector

Signavio Workflow Accelerator Connector is a RESTful web service which can be used to retrieve data from many external SQL Databases and forward this data to Signavio's Workflow Accelerator.

![Overview](docs/images/connector-network-diagram.png?raw=true "Overview")

The connector is a simple executable that can be run on most servers. In order to use the connector with Signavio's Workflow Accelerator, the connector must first be running on a server that is accessible to the public internet. 

After the connector is running and the database has been provisioned, a Workflow Accelerator administrator can [add](https://docs.signavio.com/userguide/workflow/en/integration/connectors.html#configuring-a-connector) the connector to a workspace under _Services & Connector_ menu entry. 

A process owner can then use the connector in a process to populate a drop down field dynamically using data from the database. More information about this can be found [here](https://docs.signavio.com/userguide/workflow/en/integration/connectors.html)

## Features

- Perform basic CRUD (create, read, update, delete) operations on database entries through a standard RESTful API
- Supports multiple SQL databases (MySQL, PostgresSQL, Oracle)

### Installation (on premise)

An on premise installation of the workflow connector is as simple as copying the executable file, and related configuration files from the [release page](https://github.com/signavio/workflow-connector/releases), to the appropriate directory on the server. Alternatively, the executable can be generated by compiling the source code as shown below.

### Installation (from source, on linux)

1. Download and install go from your distribution's package manager (for ubuntu `apt-get install go`) and make sure you are using version >= 1.11

2. Clone the github repository

```sh
> git clone https://github.com/signavio/workflow-connector
Cloning into 'workflow-connector'...
remote: Enumerating objects: 295, done.
remote: Counting objects: 100% (295/295), done.
remote: Compressing objects: 100% (150/150), done.
remote: Total 1231 (delta 152), reused 229 (delta 100), pack-reused 936
Receiving objects: 100% (1231/1231), 481.82 KiB | 248.00 KiB/s, done.
Resolving deltas: 100% (590/590), done.
```

3. Compile from source
```sh
> cd workflow-connector
> go build main.go
```

The executable is called `workflow-connector` and is located in `~/workflow-connector/` directory.

If you have TLS enabled and want to listen on port 443 without running the executable as root, you can set the proper permissions using the `setcap` command

```sh
> setcap 'cap_net_bind_service=+ep' ~/workflow-connector/workflow-connector
```

### Running workflow-connector as a service

The workflow connector can be configured to run on boot as a service. This can be accomplished by executing the `workflow-connector` and providing the `service` parameter with the appropriate value:

```sh
# provide the -service parameter with the `install` subcommand
> ./workflow-connector/workflow-connector -service install
```

This will install the workflow-connector as a windows service, if it is running in windows, or as a systemd unit,  if running on linux. This assumes that the user running the `-service install` command has sufficient rights to install services and the configuration files are stored in the correct directories (see Configuration below).

### Configuration

All program and environment specific configuration settings (like database connection information, username, password, etc.) should be stored in a directory named `config` which should be located in the following directories:

| Directory                            | Operating System |
| ------------------------------------ | ---------------- |
| C:/Program Files/Workflow Connector/ | windows          |
| /etc/workflow-connector/             | linux            |
| ~/.config/workflow-connector/        | linux            |

This behaviour can be overriden by providing a `--config-dir` parameter to the `workflow-connector` executable. The following configuration files will need to be modified.

#### config/config.yaml

The `config.yml` file should be configured to include settings specific to your environment. The following snippet shows an example of what this could look like. Other examples can be found in the [config.example.yml](https://github.com/signavio/workflow-connector/blob/master/config/config.example.yml).

```yml
port: 443
database:
  driver: goracle
  # url = username:password@protocol(address)/dbname?param=value
  url: bob:l120arSgHz@tcp(172.17.8.2:3306)/test?parseTime=true
tls:
  enabled: true
  publicKey: ./config/server.crt
  privateKey: ./config/server.key
auth:
  username: wfauser
  # password = Foobar
  passwordHash: "$argon2i$v=19$m=512,t=2,p=2$SUxvdmVTYWx0Q2FrZXMhISE$UgSWnBB5OkdqMAu+OfvwNLVMUijMnnmVm0kRSfmS9E8"
logging: false
```
##### port

The port to listen on. This should be port 443 if you have TLS enabled otherwise you can choose any other custom port.

##### database

The `driver` option specifies which golang driver will be used to communicate with the database. A list of supported databases and their corresponding drivers can be found on the [Supported Databases](https://github.com/signavio/workflow-connector/wiki/Supported-Databases) page. The `url` option specifies the connection parameters for the database such as username, password and address.

##### tls

Setting the `enabled` option to true will force the workflow connector web service to only use TLS. The `publicKey` and `privateKey` option should point to the location of the public key and private key that the web service will use for TLS connections. *Note*: if your TLS certificate was generated through intermediate Certificate Authorities (CAs), make sure to bundle all of the intermediate CAs' certificates in the workflow connector server's certificate. 

##### auth

The workflow connector web service will only respond to clients that provide valid HTTP basic access authentication credentials. These authentication credentials are specified in the `username` and `passwordHash` options. The `username` option stores the username required for HTTP basic access authentication as plain text, and the `passwordHash` option stores the salted and hashed password using [argon2](https://passlib.readthedocs.io/en/stable/lib/passlib.hash.argon2.html). You can use the following commands in python to generate a valid argon2 password hash for the `passwordHash` option.

1. Install passlib using python `pip`

```sh

pip install passlib argon2_cffi

```

2. Use the python shell in the command line to generate an argon2 password hash with a digest size of 32 bytes

```python

>>> from passlib.hash import argon2

>>> argon2.using(digest_size=32).hash("password")

'$argon2i$v=19$m=102400,t=2,p=8$916LEeL8f8+ZM8Z4D0EIAQ$JitmfHTb4UZxm6TqgPLdG9Sbqn5U3LHnrfO9qp3ni6U'

>>> 

```

##### logging

Setting the `logging` option to true will make the workflow-connector output debug level logging to standard output

All configuration settings in `config.yaml` can also be specified as environment variables.

For example, you can specify the database connection url by exporting the environment variable `DATABASE_URL=mysql://john:84mj29rSgHz@172.17.8.2?database=test`. This means that nested fields in the yaml file are delimited with a '_' (underscore) character when used in an environment variable. All configuration settings declared via environment variables will take precedence over the settings in your `config.yaml` file.

#### config/descriptor.json

The workflow connector also needs to know the schema of the data it will receive from the database. This is stored in the connector descriptor file `descriptor.json` and an example is provided in the [config](https://github.com/signavio/workflow-connector/blob/master/config/descriptor.json) folder. You can also refer to the [workflow documentation](https://docs.signavio.com/userguide/workflow/en/integration/connectors.html#connector-descriptor) for more information. 

## Testing ##

You can test the deployment with a local sqlite database to make sure that the RESTful API is behaving properly. The following sections demonstrate how this can be done.

### Since everyone loves coffee ###

Let's assume we want to create a workflow that can instruct an intern on how to make coffee for the rest of our team. 
On a high level the intern would need to know what style of coffee we want, what the necessary ingredients are and how to properly use the machines to make the best batch of coffee possible. If we model these requirements in a database we could end up with a similar result as to whats depicted in the following diagramm.
 
![TODO](erm.png)

Translating this diagramm to plain english would result in the following:

- A recipe contains instructions for the intern to follow. Making a recipe requires **only one** piece of equipment. A recipe of course contains **many** ingredients.
- A piece of equipment can be used in **many** different recipes.
- The database keeps track of the ingredients in stock in the `inventory` table. When the intern is shown the ingredients necessary for a recipe he or she will also be shown if there is enough of these ingredients in stock.

This database model has been translated one to one in the `config/descriptor.json` file located in this repository.

#### Okay now on to the prerequisites ####

1. Download and install sqlite

```sh
apt-get install sqlite
```

#### Populate the database ####

For testing purposes, we can execute the sqlite migration script provided in the `build/migrate-to-sqlite.sh` to create our schema and populate it with some example data. The equipment table should end up looking like this: 

**Equipment**

| id | name                        | acquisition_cost | purchase_date       |
|----|-----------------------------|------------------|---------------------|
|  1 | Bialetti Moka Express 6 cup |         25.95000 | 2017-12-12 12:00:00 |
|  2 | Sanremo CafÃ© Racer          |       8477.85000 | 2017-12-12 12:00:00 |
|  3 | Buntfink SteelKettle        |         39.95000 | 2017-12-12 12:00:00 |
|  4 | Copper Coffee Pot Cezve     |         49.95000 | 2017-12-12 12:00:00 |

#### Run the workflow connector ####

Before running the `workflow-connector` command, either edit the `config.yaml` file to include the database connection parameters and other settings, or export these settings as environment variables.

```sh
# Export environment variables
#
export PORT=:8080 DATABASE_URL=test.db DATABASE_DRIVER=sqlite3
#
# Run the connector
~/bin/workflow-connector
Listening on :8080

```

#### Exercise the REST API ####

Now we can test the functionality of the connector's REST API either in a new terminal, or using the following the [postman collection](TODO). All HTTP requests are sent using HTTP basic auth with the default username (`wfauser`) password (`Foobar`) combination here.

Go ahead and fetch the equipment with id 1 by sending a `HTTP GET` request to the connector using the `curl` command (you can `apt-get install curl` if `curl` is not yet installed):

```sh
curl --verbose --header "Authorization: Basic $(echo -n "wfauser:Foobar" | base64)" --request GET http://localhost:8080/equipment/1
# Response:
## Headers
> GET /equipment/1 HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.55.1
> Accept: */*
> Authorization: Basic d2ZhdXNlcjpGb29iYXI=
>
< HTTP/1.1 200 OK
< Content-Type: application/json
< Date: Fri, 23 Mar 2018 21:33:47 GMT
< Content-Length: 595
<
## Data
{
  "cost": {
    "amount": 119,
    "currency": "EUR"
  },
  "equipmentMaintenance": [],
  "equipmentWarranty": [],
  "id": "1",
  "name": "Stainless Steel Cooling Spiral",
  "purchaseDate": "2017-09-07T12:00:00Z"
}
```

#### Insert a new equipment in the database ####

You can create a new product by sending a `HTTP POST` to the appropriate route (here `/equipment`)

```sh
curl --verbose --header "Authorization: Basic $(echo -n "wfauser:Foobar" | base64)" --request POST --data 'name=Malt+mill+550&acquisitionCost=1270&purchaseDate=2016-09-04+11:00:00' http://localhost:8080/equipment

# Response:
## Headers
> POST /equipment HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.56.1
> Accept: */*
> Authorization: Basic d2ZhdXNlcjpGb29iYXI=
> Content-Type: application/x-www-form-urlencoded
> Content-Length: 45
>
* upload completely sent off: 45 out of 45 bytes
< HTTP/1.1 200 OK
< Content-Type: application/json
< Date: Fri, 23 Mar 2018 21:33:47 GMT
< Content-Length: 2
<
## Data
{
  "cost": {
    "amount": 1270,
    "currency": "EUR"
  },
  "equipmentMaintenance": [],
  "equipmentWarranty": [],
  "id": "5",
  "name": "Malt mill 550",
  "purchaseDate": "2017-09-04T11:00:00Z"
}
```

#### Updating an existing product ####

By sending a `HTTP PUT` to `/equipment` you can change existing entries. Let's go ahead an adjust the name of the malt mill we just added recently.


```sh
curl --verbose --header "Authorization: Basic $(echo -n "wfauser:Foobar" | base64)" --request PUT --data 'name=Malt+mill+400' http://localhost:8080/equipment/5

# Response:
## Headers
> PUT /equipment HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.56.1
> Accept: */*
> Authorization: Basic d2ZhdXNlcjpGb29iYXI=
> Content-Type: application/x-www-form-urlencoded
> Content-Length: 45
>
* upload completely sent off: 45 out of 45 bytes
< HTTP/1.1 200 OK
< Content-Type: application/json
< Date: Fri, 23 Mar 2018 21:33:47 GMT
< Content-Length: 2
<
## Data
{
  "cost": {
    "amount": 1270,
    "currency": "EUR"
  },
  "equipmentMaintenance": [],
  "equipmentWarranty": [],
  "id": "5",
  "name": "Malt mill 400",
  "purchaseDate": "2017-09-04T11:00:00Z"
}
```

#### Deleting an existing product ####

TODO: deletion is not supported at the moment.

## Support

Any inquiries for support can be sent to [support](mailto:support@signavio.com). 

## Authors

The development team at Signavio with input from Stefano Da Ros and Peter Hilton 

## Licence

GNU General Public License Version 3
